{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WF8OsY5S3ud-"
      },
      "outputs": [],
      "source": [
        "\n",
        "!rm -rf spark-3* spark-*hadoop*.tgz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark Context Creation**"
      ],
      "metadata": {
        "id": "aIW6YO6IyDcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark\n",
        "!pip install -q pyspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Set JAVA_HOME\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Start SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Market Basket\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0gye3mse3y8P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n"
      ],
      "metadata": {
        "id": "ecKtBgzH-YGs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the Data set from Kaggle**"
      ],
      "metadata": {
        "id": "GNXGqauPyXe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle credentials\n",
        "os.environ['KAGGLE_USERNAME'] = \"elahezohdi\"\n",
        "os.environ['KAGGLE_KEY'] = \"b4d81db0a12258d41bbdde98d1131209\"\n",
        "\n",
        "# Download and unzip dataset\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n",
        "!unzip -q amazon-books-reviews.zip -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4q6_RML3z9k",
        "outputId": "2bac1746-d71f-4489-ced4-a7bef8c7ec86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 96% 1.02G/1.06G [00:07<00:00, 87.2MB/s]\n",
            "100% 1.06G/1.06G [00:07<00:00, 145MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "fU85W0Vgyc6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"data/Books_rating.csv\", header=True, inferSchema=True)\n",
        "# Check schema to see column names and types\n",
        "df.printSchema()\n",
        "df.show(5)\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5t-233b4JMm",
        "outputId": "d04cf1b9-3787-427e-f582-69d1fcd43010"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Price: string (nullable = true)\n",
            " |-- User_id: string (nullable = true)\n",
            " |-- profileName: string (nullable = true)\n",
            " |-- review/helpfulness: string (nullable = true)\n",
            " |-- review/score: string (nullable = true)\n",
            " |-- review/time: string (nullable = true)\n",
            " |-- review/summary: string (nullable = true)\n",
            " |-- review/text: string (nullable = true)\n",
            "\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|1882931173|Its Only Art If I...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
            "|summary|                  Id|               Title|               Price|            User_id|profileName| review/helpfulness|      review/score|         review/time|      review/summary|         review/text|\n",
            "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
            "|  count|             3000000|             2999792|              482421|            2437750|    2437800|            2999633|           2999870|             2999973|             2999935|             2999957|\n",
            "|   mean|1.0568515696607149E9|   2012.796651763537|  21.767951161877054|  18.29299003322259|        NaN|3.285048033703448E8| 1656.860421970827|1.1270533345949814E9|            Infinity|  9.95368319174848E8|\n",
            "| stddev| 1.284488524833734E9|  1536.7533549608797|   26.21155241772817|  21.99284402625621|        NaN| 5.46938050416698E8|1427549.9863179324|1.6715719402140123E8|                 NaN| 4.227222142880359E8|\n",
            "|    min|          0001047604|  \"\"\" Film technique|              \"\" and| \"\" Film acting \"\"\"|          \u001a|      #1 Bestse...\"|   & Algorithms\"\"\"| \"\"Cards of your ...| \"\"The Child Manu...|\u0011The Tao of Muham...|\n",
            "|    max|          B0064P287I|you can do anythi...|: A guide to loca...|      AZZZZW74AAX75|    ~~~~~~~|                 xo|         thersites|        sideshowmatt|~~~~~~~~~~~~~~~~~...|~~~~~~~~~~~~~~~~~...|\n",
            "+-------+--------------------+--------------------+--------------------+-------------------+-----------+-------------------+------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only User_id and Title and drop nulls\n",
        "df = df.select(\"User_id\", \"Title\").dropna()\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi7e9ENZ4Jnc",
        "outputId": "12d72960-1b31-4f26-b721-f8f95faf1e80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+\n",
            "|       User_id|               Title|\n",
            "+--------------+--------------------+\n",
            "| AVCGYZL8FQQTD|Its Only Art If I...|\n",
            "|A30TK6U7DNS82R|Dr. Seuss: Americ...|\n",
            "|A3UH4UZ4RSVO82|Dr. Seuss: Americ...|\n",
            "|A2MVUWT453QH61|Dr. Seuss: Americ...|\n",
            "|A22X4XUPKF66MR|Dr. Seuss: Americ...|\n",
            "+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the baskets**"
      ],
      "metadata": {
        "id": "tr51cIVyypY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower, regexp_replace, trim, collect_set, size\n",
        "\n",
        "\n",
        "# Clean and sample\n",
        "df_clean = df.select(\"User_id\", \"Title\").dropna()\n",
        "df_clean = df_clean.withColumn(\"Title\", lower(regexp_replace(\"Title\", r\"[^a-zA-Z0-9 ]\", \"\")))\n",
        "df_clean = df_clean.withColumn(\"Title\", regexp_replace(\"Title\", r\"\\s+\", \" \"))\n",
        "df_clean = df_clean.withColumn(\"Title\", trim(df_clean[\"Title\"]))\n",
        "df_clean = df_clean.sample(False, 0.01, seed=42)\n",
        "\n",
        "# Group by user\n",
        "df_grouped = df_clean.groupBy(\"User_id\").agg(collect_set(\"Title\").alias(\"basket\"))\n",
        "df_grouped = df_grouped.filter(size(\"basket\") > 1)\n",
        "\n",
        "# Print a few rows\n",
        "df_grouped.show(5, truncate=False)\n",
        "\n",
        "# Extract baskets\n",
        "basket_rows = df_grouped.select(\"basket\").limit(10000).toLocalIterator()\n",
        "baskets = [row.basket for row in basket_rows]\n",
        "\n",
        "# Show samples and stats\n",
        "print(\"First basket:\", baskets[0])\n",
        "print(\"Number of baskets:\", len(baskets))\n",
        "lengths = [len(b) for b in baskets]\n",
        "print(\"Max basket size:\", max(lengths))\n",
        "print(\"Min basket size:\", min(lengths))\n",
        "print(\"Average basket size:\", sum(lengths)/len(lengths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Wi7JP_1sqk",
        "outputId": "6bbd5e7c-a926-48b9-d7a3-929452e6c3f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|User_id       |basket                                                                                                                                                                                                              |\n",
            "+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|A103U0Q3IKSXHE|[what clients love a field guide to growing your business, thunder and lightning cracking open the writers craft]                                                                                                   |\n",
            "|A10872FHIJAKKD|[the lord of the rings the fellowship of the ring bbc audio collection, the hobbit]                                                                                                                                 |\n",
            "|A10HWJXUG67E7I|[the count of monte cristo, antisemitism myth and hate from antiquity to the present, road unseen, reckless disregard how liberal democrats undercut our military endanger our soldiers and jeopardize our security]|\n",
            "|A10K3DLOEVMKW3|[cast a yellow shadow, charlotte gray, shilling for candlesaud csst, shutter island]                                                                                                                                |\n",
            "|A10T0OW97SFBB |[the wind in the willows, jesus christ and mythology, wuthering heights]                                                                                                                                            |\n",
            "+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "First basket: ['what clients love a field guide to growing your business', 'thunder and lightning cracking open the writers craft']\n",
            "Number of baskets: 1271\n",
            "Max basket size: 56\n",
            "Min basket size: 2\n",
            "Average basket size: 2.8088119590873326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baskets_rdd = sc.parallelize(baskets)\n"
      ],
      "metadata": {
        "id": "yJsVXsGs9Lum"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The hash table**"
      ],
      "metadata": {
        "id": "gn2Ff37SywwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Hash Table\n",
        "hash = baskets_rdd.flatMap(lambda line: line).distinct()\n",
        "hash = hash.zipWithIndex()\n",
        "hash_table = hash.collectAsMap()\n"
      ],
      "metadata": {
        "id": "FmI8M961LVu-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hash baskets\n",
        "def hashing(basket):\n",
        "    return {hash_table[title] for title in basket if title in hash_table}\n",
        "\n",
        "baskets_hashed = baskets_rdd.map(hashing)"
      ],
      "metadata": {
        "id": "c-dMjnX-LYrk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A-PRIORI ALGORITHM**"
      ],
      "metadata": {
        "id": "RFgelheey3zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def a_priori(baskets_collection, support, hash_table):\n",
        "    print(\"Frequent singletons\")\n",
        "    first_pass = baskets_collection.flatMap(lambda basket: [(item, 1) for item in basket]) \\\n",
        "                                   .reduceByKey(lambda x, y: x + y) \\\n",
        "                                   .filter(lambda x: x[1] >= support)\n",
        "\n",
        "    if first_pass.isEmpty():\n",
        "        print(\"⚠️ No frequent singletons — try lowering support\")\n",
        "        return\n",
        "\n",
        "    print(\"Number of frequent singletons:\", first_pass.count())\n",
        "    most_common = first_pass.max(lambda x: x[1])[0]\n",
        "    print(\"Most frequent singleton:\", [k for k, v in hash_table.items() if v == most_common][0])\n",
        "    print()\n",
        "\n",
        "    freq_itemsets = set(first_pass.map(lambda x: (x[0],)).collect())\n",
        "    k = 2\n",
        "\n",
        "    while True:\n",
        "        print(f\"Itemsets of size {k}\")\n",
        "        candidates = baskets_collection.flatMap(lambda basket:\n",
        "            [(combo, 1) for combo in combinations(sorted(basket), k)\n",
        "             if all(sub in freq_itemsets for sub in combinations(combo, k - 1))]) \\\n",
        "            .reduceByKey(lambda x, y: x + y) \\\n",
        "            .filter(lambda x: x[1] >= support)\n",
        "\n",
        "        if candidates.isEmpty():\n",
        "            print(f\"No frequent itemsets of size {k}\")\n",
        "            print(\"✅ Apriori terminated — no more frequent itemsets.\")\n",
        "            break\n",
        "\n",
        "        print(f\"Number of frequent itemsets of size {k}:\", candidates.count())\n",
        "\n",
        "        # Display the most frequent itemset of this size\n",
        "        top_itemset = candidates.max(lambda x: x[1])\n",
        "        top_readable = [k for k, v in hash_table.items() if v in top_itemset[0]]\n",
        "        print(\"Most frequent itemset:\", top_readable)\n",
        "\n",
        "        freq_itemsets = set(candidates.map(lambda x: x[0]).collect())\n",
        "        print()\n",
        "        k += 1\n"
      ],
      "metadata": {
        "id": "DuAkpjeL_CXC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Apriori with support = 2 or 3 to start\n",
        "support = 2\n",
        "a_priori(baskets_hashed, support, hash_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue_MiF7tAFAo",
        "outputId": "72a79b9c-2a3a-44f4-b970-b827db7d41cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent singletons\n",
            "Number of frequent singletons: 381\n",
            "Most frequent singleton: the hobbit\n",
            "\n",
            "Itemsets of size 2\n",
            "Number of frequent itemsets of size 2: 24\n",
            "Most frequent itemset: ['the hobbit there and back again', 'the hobbitt or there and back again illustrated by the author']\n",
            "\n",
            "Itemsets of size 3\n",
            "Number of frequent itemsets of size 3: 2\n",
            "Most frequent itemset: ['pride and prejudice', 'emma signet classics', 'sense sensibility']\n",
            "\n",
            "Itemsets of size 4\n",
            "No frequent itemsets of size 4\n",
            "✅ Apriori terminated — no more frequent itemsets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(baskets[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGYSdSKxAHOf",
        "outputId": "234b2146-1a9b-4850-cc80-22567e4ce8de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what clients love a field guide to growing your business', 'thunder and lightning cracking open the writers craft']\n",
            "['the lord of the rings the fellowship of the ring bbc audio collection', 'the hobbit']\n",
            "['the count of monte cristo', 'antisemitism myth and hate from antiquity to the present', 'road unseen', 'reckless disregard how liberal democrats undercut our military endanger our soldiers and jeopardize our security']\n",
            "['cast a yellow shadow', 'charlotte gray', 'shilling for candlesaud csst', 'shutter island']\n",
            "['the wind in the willows', 'jesus christ and mythology', 'wuthering heights']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jueG7HW3ZE4q"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}